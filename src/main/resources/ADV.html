<!DOCTYPE definition [
<!ENTITY ndash "&#8211;">
<!ENTITY nbsp "&#160;">
<!ENTITY mdash "&#8212;">
<!ENTITY hellip "&#8230;">
<!ENTITY rsquo "&#8217;">
<!ENTITY amp "&#38;">
<!ENTITY lsquo "&#8216;">
<!ENTITY agrave "&#192;">
<!ENTITY ldquo "&#8220;">
<!ENTITY rdquo "&#8221;">
]>
<a>
		<div id="session_10384" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=10384" class="openInPopup">
					
						<span class="abbreviation">ADV303 - </span>
					
					<span class="title">MediaMathâ€™s Data Revolution with Amazon Kinesis and Amazon EMR</span>
				</a>
        
				
					<span class="abstract">Collecting and processing terabytes of data per day is a challenge for any technology company. As marketers and brands become more sophisticated consumers of data, enabling granular levels of access to targeted subsets of data from outside your firewalls presents new challenges. This session discusses how to build scalable, complex, and cost-effective data processing pipelines using Amazon Kinesis, Amazon EC2 Spot Instances, Amazon EMR, and Amazon Simple Storage Service (S3). Learn how MediaMath revolutionized their data delivery platform with the help of these services to empower product teams, partners, and clients. As a result, a number of innovative products and services are delivered on top of terabytes of online user behavior. MediaMath covers their journey from legacy batch processing and vendor lock-in to a new world where the raw materials to build advanced lookalike models, optimization algorithms, or marketing attribution models are readily available to any engineering team in real time, substantially reducing the time &mdash;&nbsp;and cost&nbsp;&mdash;&nbsp;of innovation.</span>
				
				
					<small class="length">45 minutes</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Aditya Krishnan &ndash; Sr. Product Manager with Amazon Web Services<br/>Edward Fagin &ndash; VP, Engineering with MediaMath<br/>Ian Hummel &ndash; Sr. Director, Data Platform with MediaMath<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
				
				
			</div>
		</div>
	
		
		<div id="session_10544" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=10544" class="openInPopup">
					
						<span class="abbreviation">ADV402 - </span>
					
					<span class="title">Beating the Speed of Light with Your Infrastructure in AWS</span>
				</a>
        
				
					<span class="abstract">With Amazon Web Services it's possible to serve the needs of modern high performance advertising without breaking the bank. This session covers how AdRoll processes more than 60 billion requests per day in less than 100 milliseconds each using Amazon DynamoDB, Auto Scaling, and Elastic Load Balancing. This process generates more than 2 GB of data every single second, which will be processed and turned into useful models over the following hour. We discuss designing systems that can answer billions of latency-sensitive global requests every day and look into some tricks to pare down the costs.</span>
				
				
					<small class="length">45 minutes</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Siva Raghupathy &ndash; Principal Solutions Architect with Amazon Web Services<br/>Valentino Volonghi &ndash; CTO with AdRoll<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
				
				
			</div>
		</div>
	
		
		<div id="session_8808" class="resultRow sessionRow ">
			<div class="detailColumn">
				
				<a href="sessionDetail.ww?SESSION_ID=8808" class="openInPopup">
					
						<span class="abbreviation">ADV403 - </span>
					
					<span class="title">Dynamic Ad Performance Reporting with Amazon Redshift: Data Science and Complex Queries at Massive Scale</span>
				</a>
        
				
					<span class="abstract">Delivering deep insight on advertising metrics and providing customers easy data access becomes a challenge as scale increases. In this session, Neustar, a global provider of real-time analytics, shows how they use Redshift to help advertisers and agencies reach the highest-performing customers using data science&nbsp;at scale. Neustar dives into the queries they use to determine how best to target ads based on their real reach, how much to pay for ads using multi-touch attribution, and how frequently to show ads. Finally, Neustar discusses how they operate a fleet of Redshift clusters to run workloads in parallel and generate daily reports on billions of events within hours. Session includes how Neustar provides daily feeds of event-level data to their customers for ad-hoc data science.</span>
				
				
					<small class="length">45 minutes</small>
				
				
					<small class="type">Breakout Session</small>
				
				
					<small class="speakers">Vidhya Srinivasan &ndash; Senior Manager, Software Development with Amazon Web Services<br/>Timon Karnezos &ndash; Director, Infrastructure with NeuStar<br/></small>
				
				<span class="track"></span>
				<span class="scheduleStatus">
					
					
					
					
				</span>
			</div>
			<div class="actionColumn">
				


				
					
				
				
			</div>
		</div>
	


	
</a>
